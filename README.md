# deeplearningbook


introduction to maching learning
With a few rules, AI is able to tackle simple problems with great accomplishment in early days. Nowadays, we are facing much more complicate.
However subjective and intuitive knowledge invovled tasks remain diffult for AI to rival human. So it's said that "One of the key challenges in
artificial intelligence is how to get this informal knowledge into a computer". The complexity behind various problems required that knowledge are 
to be acquired, instead of hard coded. Machine learning comes to rescue here.

from maching learning to deep learning
Machine learning algorithms relays heavily on the representation of the data, which is known as feature. It can be difficult to extract the proper features
from raw data. Deep learning can solve this problem automatically, this befinits so much to building a powerful AI systems that's capble of coping with  
complicate situations. In my view, it's another useful tool invented to analyse problems, which means you can break hard problems into small and 
easy piceces with it, perform some actions on these parts, and concludes somewhere. 

Overview
This books has been organized into three parts. Part I introduces some fundamental knowledges to understand deep learning. Part II is a practical guideance 
to build a working system.Part III help those researchers and experts in this area out.

History
Deep learning is not a novel idea, it dates back to 1940s. The earliest predecessors of modern deep learning were simple linear models. Linear models has limits.
A few key concepts remaining central to today's deep learning arouse during 1980s, includes distributed representation(use features to represent input), back propagation
to train neatral network.



Part I
Linear Algebra
Scalars,Vectors,Matrices, Tensors
transpose, broadcasting,element-wise product or Hadamard product, dot product,matrix inversion(useful as a theoretical tool, should not be used in practice),

linear combination 
A square matrix(n*n) with linearly dependent columns( independent columns is n*m) is known as singular.
Norms are functions mapping vectors to non-negative values,  used to measure the size of vectors.
Squared L2 norms maybe undesirable because it increases very slowly near the origin. When it's important to discriminate between exactly zero and near zero, L1 norm is recommended.
max norms is the max absolute value of the elments in the vector.

The most common way to measure the matrix size is Frobenius norm, analogous to L2 norm of a vector.
diagonal matrices is computationally effcient in matrix multiplying, and so is its inverse.(In many cases, we may derive some very general machine learning algorithm in terms of arbitrary matrices,but obtain a less expensive (and less descriptive) algorithm by restricting some matrices to be diagonal)
Non-square diagonal matrices do not have inverses but it is still possible to multiply by them cheaply either by concatenating some zeros, or by discarding some elements.

Symmetric matrices often arise when the entries are generated by some function of two arguments that does not depend on the order of the arguments.
the inverse of an orthogonal matrix  is equal to its transpose, that makes orthogonal matrix interesting.
eigen decomposition is one of the most widely used matrix decompision methods, it aims at finding some properties that are universal by breaking matrices into parts. not every matrix can be decomposed into eigenvalues and eigenvectors.
the formal eigen decomposition is composed of three parts: diagnal matrix of eigen values, eigenvectors matrix and its inverse. 
Specifically, every real symmetric matrix can be decomposed into an expression using only real-valued eigenvectors and eigenvalues:diagnal matrix of eigen values, diageigenvectors matrix and its tranpose(inverse). This means, in the real symmetric matrix case,
the eigen decomposition can be simplified.

SVD is another matrix decomposition, every real matrix has a singular value decomposition. non-square matrix cannot be eigendecomposition, but svd is applicable here.
A(m×n) = U(m×m orthogonal matrices) * D(m×n diagonal matrix)* transpose of V(n×n orthogonal matrices).The elements along the diagonal of D are known as the singular values of the matrix A. the most useful feature of SVD
is to perform matrix inversion to non-square matrix.
the trace operator make it easy to use proper notation to denote complicate operations, invariant to cyclic permutation.
the determinant of a square matrix is a function mapping matrices to real scalars, it's equal to product of all the eigenvalues of matrix.

The PCA is comprehensive in 1d case, however you need 






a random variable is just a description of the states that are possible; it must be coupled with a probability distribution that specifies how likely each of these states are

The probability mass function(PMF) maps from a state of a random variable to the probability of that random variable taking on that state.probability density function (PDF) is used in continuous random variables.

Sometimes we know the probability distribution over a set of variables and we want to know the probability distribution over just a subset of them. The probability distribution over the subset is known as the marginal probability distribution.

In many cases, we are interested in the probability of some event, given that some other event has happened. This is called a conditional probability. 

Computing the consequences of an action is called making an intervention query. conditional probability is not the same as causal modeling.(e.g. The conditional probability that a person is from Germany given that they speak German is quite high, but if a randomly selected person is taught to speak German, their country of origin does not change. )

The covariance gives some sense of how much two values are linearly related to each other, as well as the scale of these variables. High absolute values of the covariance mean that the values change very much and are both far 
from their respective means at the same time. If the sign of the covariance is positive, then both variables tend to take on relatively high values simultaneously. If the sign of the covariance is negative, then one variable 
tends to take on a relatively high value at the times that the other takes on a relatively low value and vice versa.
Other measures such as correlation normalize the contribution of each variable in order to measure only how much the variables are related, rather than also being affected by the scale of the separate variables

Independence is a stronger requirement than zero covariance,it is possible for two variables to be dependent but have zero covariance. 

The diagonal elements of the covariance give the variance.

The Bernoulli and multinoulli distributions are sufficient to describe any distribution model with discrete variables for it is feasible to simply enumerate all of the states.

The most commonly used distribution over real numbers is the normal distribution, also known as the Gaussian distribution.

the normal distribution is a good default choice In the absence of prior knowledge about what form a distribution over the real numbers should take.

In the context of deep learning, we often want to have a probability distribution with a sharp point at x = 0 . To accomplish this, we can use the exponential distribution.
A closely related probability distribution that allows us to place a sharp peak of probability mass at an arbitrary point µ is the Laplace distribution.

In some cases, we wish to specify that all of the mass in a probability distribution clusters around a single point. This can be accomplished by defining a PDF using the Dirac delta function
A common use of the Dirac delta distribution is as a component of an empirical distribution. The Dirac delta distribution is only necessary to define the empirical distribution over continuous variables.For discrete 
variables, the situation is simpler: an empirical distribution can be conceptualized as a multinoulli distribution, with a probability associated to each possible input value that is simply equal to the empirical 
frequency of that value in the training set.


It is also common to define probability distributions by combining other simpler probability distributions.In Chapter 16, we explore the art of building complex probability distributions from simple ones in more detail.
The mixture model allows us to briefly glimpse a concept that will be of paramount importance later—the latent variable. A latent variable is a random variable that we cannot observe directly. 

The logistic sigmoid is commonly used to produce the φ parameter of a Bernoulli distribution because its range is (0,1), which lies within the valid range of values for the φ parameter.

The softplus function can be useful for producing the β or σ parameter of a normal distribution because its range is (0,∞).  The softplus function is intended as a smoothed version of the positive part function, x + = max{0, x}. 

A proper formal understanding of continuous random variables and probability density functions requires developing probability theory in terms of a branch of mathematics known as measure theory.

The basic intuition behind information theory is that learning that an unlikely event has occurred is more informative than learning that a likely event has occurred. A message saying “the sun rose this morning” is so uninformative as to be unnecessary to send, but a message saying “there was a solar eclipse this morning” is very informative.
the self-information of an event x = x  I(x) = − log P(x) is defined by meeting the following three requirements:
1)Likely events should have low information content
2)Less likely events should have higher information content
3)Independent events should have additive information. For example, finding out that a tossed coin has come up as heads twice should convey twice as much information as finding out that a tossed coin has come up as heads once.	

Kullback-Leibler (KL) divergence can measure how different two separate probability distributions P(x) and Q(x) over the same random variable x distributions are. The KL divergence is 0 if and only if P and Q are the same distribution in
the case of discrete variables. However, it is not a true distance measure because it is not symmetric for some P and Q. 

A quantity that is closely related to the KL divergence is the cross-entropy.Minimizing the cross-entropy with respect to Q is equivalent to minimizing the KL divergence.

When we represent the factorization of a probability distribution with a graph, we call it a structured probabilistic model or graphical model.

One example of a function that must be stabilized against underflow and overflow is the softmax function. Both of these difficulties can be resolved by instead evaluating softmax(z) where z = x − maxi xi. 

Theano is an example of a software package that automatically detects and stabilizes many common numerically unstable expressions that arise in the context of deep learning.

Conditioning refers to how rapidly a function changes with respect to small changes in its inputs. Functions that change rapidly when their inputs are perturbed slightly can be problematic for scientific computation because rounding errors in the inputs can result in large changes in the output.

Consider the function f(x) = A−1x. When A ∈ Rn×n has an eigenvalue
decomposition, its condition number is the ratio of the magnitude of the largest and smallest eigenvalue. When this number is large, matrix inversion is particularly sensitive to error in the input.

Karush–Kuhn–Tucker (KKT) approach1 provides a very general solution to constrained optimization. With the KKT approach, we introduce a new function called the generalized Lagrangian or generalized Lagrange function.

4.5 is an example showing how to solve it using gradient-based optimization .

Chapter 5 delivers several principles :
Regularization is one of the central concerns of the field of machine learning, rivaled in its importance only by optimization.

validation set is part of the training set, and served as estimate the generalization error during or after training, allowing for the hyperparameters to be updated accordingly.
k-fold cross-validation is used when test set is small.

An important concept underlying many ideas in machine learning is that of a manifold.A manifold is a connected region.

Part II
These chapters are the most important for a practitioner—someone who wants to begin implementing and using deep learning algorithms to solve real-world problems today.

chapter 6 Deep Feedforward Networks/multilayer perceptrons(MLP)/feedforward neural networks
modern neural network is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization, occasionally drawing some insights from what we
know about the brain, rather than as models of brain function.

linear models() may be fit efficiently and reliably, but is limited to understand the non-linear interactions between inputs. it either use a generic non-linear transform or manually engineer such a transform. The strategy of deep learning 
is able to learn this non-linear transform. The advantage is that the human designer only needs to find the right general function family rather than finding precisely the right function.

The first example with deep feedforward networks is learnig XOR logic . treat this as a regression problem and use a mean squared error loss function.(there are more appropriate approaches for modeling binary data)
f(x;W,c,w,b) = w'max{0,W'x + c} + b.
the nonlinearity of a neural network causes most interesting loss functions to become non-convex, gradient-based optimizers that merely drive the cost function to a very low value, rather than the linear equation solvers used to train linear regression models or the convex optimization algorithms with global convergence guarantees used to train logistic regression or SVMs.



An important aspect of the design of a deep neural network is the choice of the cost function.
Most modern neural networks are trained using maximum likelihood. This means that the cost function is simply the negative log-likelihood, equivalently described as the cross-entropy between the training data and the model distribution.

The negative log-likelihood helps to relieve the activation functions or the output units saturate problem.

Many output units involve an exp function that can saturate when its argument is very negative. The log function in the negative log-likelihood cost function undoes the exp of some output units. 

calculus of variations is used to solve the optimize problem that find a specific function we desire to maximize/minimize, instead of choosing a set of parameters of a known function.

The choice of cost function is tightly coupled with the choice of output unit.Most of the time, we simply use the cross-entropy between the data distribution and the model distribution.

linear units do not saturate, which makes it easy for gradientbased optimization algorithms

using sigmoid output units combined with maximum likelihood to ensures there is always a strong gradient whenever the model has the wrong answer. linear model saturate when the value 




























